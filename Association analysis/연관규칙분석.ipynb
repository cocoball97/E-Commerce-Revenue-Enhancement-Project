{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fe7cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 협업 필터링에는 2가지가 있음\n",
    "\n",
    "# 1. 고객별 개개인 추천시스템 (사용자 추천 서비스)\n",
    "# 2. 일반적으로 관련된 상품 추천 (아이템 추천 서비스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89314bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객을 전부 넣어야 하는 이유\n",
    "\n",
    "# 고객이 상품을 하나만 구매할 때 해당 상품이 더 많이 등장한다는 사실로부터 우리는 다음과 같은 정보를 얻을 수 있습니다.\n",
    "\n",
    "# 상품의 인기도: 해당 상품이 다른 상품들보다 인기가 높다면, 고객이 단 하나의 상품을 구매할 때에도 해당 상품이 더 많이 등장할 가능성이 높아집니다. \n",
    "# 이는 해당 상품이 고객들에게 매력적인 제품이라는 증거가 됩니다.\n",
    "\n",
    "# 고객의 취향: 고객이 단 하나의 상품을 선택할 때 해당 상품이 다른 상품들보다 더 많이 등장한다면,\n",
    "# 이는 해당 상품이 고객의 취향에 맞는 제품이라는 증거가 됩니다. 이를 통해 상품을 더욱 정확하게 타겟팅하여 마케팅 전략을 수립할 수 있습니다.\n",
    "\n",
    "########\n",
    "# 크로스셀링 기회: 단 하나의 상품만을 구매하는 고객에게 해당 상품과 관련된 다른 상품들을 제안함으로써 추가적인 구매 기회를 창출할 수 있습니다.  \n",
    "# 예를 들어, 만약 해당 상품이 어떤 다른 제품과 함께 사용하는 것이 일반적이라면, 해당 제품과 함께 구매할 만한 크로스셀링 기회가 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77ca4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 개만 구매하는 고객을 빼는 경우\n",
    "\n",
    "# 한 개만 구매하는 고객을 빼고 연관분석을 수행하는 경우는 \"단일 구매자 분석\"이라고도 불리며, 이 경우 다음과 같은 정보를 얻을 수 있습니다.\n",
    "\n",
    "# 상품 번들링 기회: 연관분석을 통해 다른 고객들이 함께 구매하는 상품들을 파악함으로써, 해당 상품과 함께 구매되는 다른 상품들을 제안할 수 있습니다. \n",
    "# 이를 통해 상품 번들링 기회를 찾아내어 매출을 높일 수 있습니다.\n",
    "\n",
    "# 상품 포지셔닝: 연관분석 결과를 통해 어떤 상품들이 함께 구매되는지 파악함으로써, 해당 상품의 위치와 경쟁 업체와의 차별화 전략을 수립할 수 있습니다.\n",
    "\n",
    "# 상품 품질 개선: 연관분석을 통해 함께 구매되는 상품들 중에 불만족스러운 상품이 있다면, 해당 상품의 품질을 개선하여 고객 만족도를 높일 수 있습니다.\n",
    "\n",
    "# 고객 세분화: 단일 구매자 분석을 통해 한 개만 구매하는 고객들의 구매 패턴을 파악할 수 있습니다. \n",
    "# 이를 기반으로 고객을 세분화하여 타겟팅을 더욱 정확하게 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68982f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개짜리도 포함시킨 이유\n",
    "\n",
    "# 만약, 여러 번 구매하지만 상품 하나만 구매하는 경우가 다른 고객들과 함께 구매하는 상품들의 교집합이 크다면,\n",
    "# 들을 제외하면 추천시스템이 불완전해질 수 있습니다. 따라서, 이러한 경우에는 여러 번 구매하지만 상품 하나만 구매하는 경우도 모델에 포함시켜야 합니다.\n",
    "\n",
    "# 다른 고객들과 함께 구매하는 상품들의 교집합이 크다: 여러 번 구매하지만 상품 하나만 구매하는 경우가 다른 고객들과 함께 구매하는 상품들이 많이 겹친다\n",
    "\n",
    "\n",
    "# 그러나, 여러 번 구매하지만 상품 하나만 구매하는 경우가 다른 고객들과 함께 구매하는 상품들의 교집합이 작거나 없는 경우에는 \n",
    "# 이들을 모델에서 제외시켜도 괜찮습니다. 이러한 경우에는 다른 고객들과 구매 패턴이 다르기 때문에,\n",
    "# 이들의 데이터를 모델에 포함시키면 노이즈로 작용하여 추천 정확도를 떨어뜨릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5fb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.rc(\"font\",family = \"NaNumGothic\")\n",
    "matplotlib.rc(\"axes\",unicode_minus = False) # 음수표시 \n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc9e84",
   "metadata": {},
   "source": [
    "# 중분류물품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c3767c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(중분류물품명).csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76f7096a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>논지엠오유정란</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세안비누$세안비누$치약/칫솔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>치약/칫솔$위생용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>추출/농축액</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>프리믹스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189363</th>\n",
       "      <td>논지엠오유정란$오이$파프리카$파프리카$기타양념$포도(혼합포도)$기타양념</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189364</th>\n",
       "      <td>콩$건대추$화본</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189365</th>\n",
       "      <td>콩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189366</th>\n",
       "      <td>양파$기름$깐마늘$당근$우유/산양유$중파$어묵$간장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189367</th>\n",
       "      <td>오이$김$햄/소시지/훈제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189368 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "0                                       논지엠오유정란\n",
       "1                               세안비누$세안비누$치약/칫솔\n",
       "2                                    치약/칫솔$위생용품\n",
       "3                                        추출/농축액\n",
       "4                                          프리믹스\n",
       "...                                         ...\n",
       "189363  논지엠오유정란$오이$파프리카$파프리카$기타양념$포도(혼합포도)$기타양념\n",
       "189364                                 콩$건대추$화본\n",
       "189365                                        콩\n",
       "189366             양파$기름$깐마늘$당근$우유/산양유$중파$어묵$간장\n",
       "189367                            오이$김$햄/소시지/훈제\n",
       "\n",
       "[189368 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5d78512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df 학습\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d9b29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee2c5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing 42 combinations | Sampling itemset size 2\n"
     ]
    }
   ],
   "source": [
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28cc2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "020f8af1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>all-confidence</th>\n",
       "      <th>collective strength</th>\n",
       "      <th>cosine similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, all-confidence, collective strength, cosine similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules_df.sort_values(by='lift',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f636c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc820dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_association.to_csv('연관규칙(중분류물품명).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde53cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "177ad336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b7cdace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"font\",family = \"NaNumGothic\")\n",
    "matplotlib.rc(\"axes\",unicode_minus = False) # 음수표시 \n",
    "\n",
    "# 연관 규칙 그래프 생성\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "G.add_nodes_from(['과즙', '스낵', '김가공', '식빵', '두부', '즉석떡'])\n",
    "\n",
    "# 엣지 추가\n",
    "G.add_edge('과즙', '스낵')\n",
    "G.add_edge('스낵', '과즙')\n",
    "G.add_edge('김가공', '스낵')\n",
    "G.add_edge('스낵', '김가공')\n",
    "G.add_edge('스낵', '식빵')\n",
    "# ... 엣지 추가 ...\n",
    "\n",
    "# 노드 그리기\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=1000)\n",
    "\n",
    "# 엣지 그리기\n",
    "nx.draw_networkx_edges(G, pos, width=1, alpha=0.7, arrows=True, edge_color='gray')\n",
    "\n",
    "# 노드 라벨 그리기\n",
    "nx.draw_networkx_labels(G, pos, font_size=16, font_family='sans-serif')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "597b81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch 최적의 파라미터 불가. 파라미터 조정을 도메인 바탕으로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6745f",
   "metadata": {},
   "source": [
    "# 남자만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f121b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 78 combinations | Sampling itemset size 3e 2\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명)남자.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명)남자.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c87e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8112a9d9",
   "metadata": {},
   "source": [
    "# 물품명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f096503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유정란/친환경</td>\n",
       "      <td>통밀식빵</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>키토산비누</td>\n",
       "      <td>키토산비누</td>\n",
       "      <td>물사랑치약</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>물사랑치약</td>\n",
       "      <td>면생리대</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>흑염소진액</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>곡물쿠키믹스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2    3    4    5    6    7    8    9  ...   47   48  \\\n",
       "0  유정란/친환경   통밀식빵    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "1    키토산비누  키토산비누  물사랑치약  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2    물사랑치약   면생리대    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "3    흑염소진액    NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "4   곡물쿠키믹스    NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "\n",
       "    49   50   51   52   53   54   55   56  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명).csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be1d5f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 78 combinations | Sampling itemset size 3e 2\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명).csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbdd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1411d0c1",
   "metadata": {},
   "source": [
    "# 연령별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7890d54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22952 combinations | Sampling itemset size 2\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 20대.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 20대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a857344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22952 combinations | Sampling itemset size 2\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 20대.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "\n",
    "\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 20대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59621f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 273 combinations | Sampling itemset size 32\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 30대.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 30대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def28d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing 2450 combinations | Sampling itemset size 2\r\n",
      "Processing 366 combinations | Sampling itemset size 3\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 40대.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 40대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c275e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing 2450 combinations | Sampling itemset size 2\r\n",
      "Processing 597 combinations | Sampling itemset size 3\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 50대.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 50대.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834601d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing 2450 combinations | Sampling itemset size 2\r\n",
      "Processing 483 combinations | Sampling itemset size 3\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명) 60대 이상.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명) 60대 이상.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba6b64",
   "metadata": {},
   "source": [
    "# 연령별 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea6823f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명).csv\",index_col=0)\n",
    "df2= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명) 20대.csv\",index_col=0)\n",
    "df3= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명) 30대.csv\",index_col=0)\n",
    "df4= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명) 40대.csv\",index_col=0)\n",
    "df5= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명) 50대.csv\",index_col=0)\n",
    "df6= pd.read_csv(\"/home/piai/강의파일/프로젝트/연관규칙 분석 결과/연관규칙 결과/연관규칙(물품명) 60대 이상.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1f7c99b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['antecedents'] = df['antecedents'].str.replace('frozenset','')\n",
    "df['consequents'] = df['consequents'].str.replace('frozenset','')\n",
    "df = df[['antecedents','consequents','lift']]\n",
    "df2['antecedents'] = df2['antecedents'].str.replace('frozenset','')\n",
    "df2['consequents'] = df2['consequents'].str.replace('frozenset','')\n",
    "df2 = df[['antecedents','consequents','lift']]\n",
    "df3['antecedents'] = df3['antecedents'].str.replace('frozenset','')\n",
    "df3['consequents'] = df3['consequents'].str.replace('frozenset','')\n",
    "df3 = df[['antecedents','consequents','lift']]\n",
    "df4['antecedents'] = df4['antecedents'].str.replace('frozenset','')\n",
    "df4['consequents'] = df4['consequents'].str.replace('frozenset','')\n",
    "df4 = df[['antecedents','consequents','lift']]\n",
    "df5['antecedents'] = df5['antecedents'].str.replace('frozenset','')\n",
    "df5['consequents'] = df5['consequents'].str.replace('frozenset','')\n",
    "df5 = df[['antecedents','consequents','lift']]\n",
    "df6['antecedents'] = df6['antecedents'].str.replace('frozenset','')\n",
    "df6['consequents'] = df6['consequents'].str.replace('frozenset','')\n",
    "df6 = df[['antecedents','consequents','lift']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a340f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.578839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.578839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.547957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.547957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.209997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.209997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.195841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'양파'})</td>\n",
       "      <td>1.195841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.170426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'동물복지유정란'})</td>\n",
       "      <td>1.170426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.163668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.163668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.155821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.155821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>1.150401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "      <td>({'당근'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.150401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.122162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.122162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>1.101436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>({'콩나물'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.101436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>1.100126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "      <td>({'찌개용두부'})</td>\n",
       "      <td>({'유정란/친환경'})</td>\n",
       "      <td>1.100126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>1.098418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "      <td>({'두부'})</td>\n",
       "      <td>({'오이'})</td>\n",
       "      <td>1.098418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      antecedents    consequents      lift    antecedents    consequents  \\\n",
       "23    ({'찌개용두부'})      ({'콩나물'})  1.578839    ({'찌개용두부'})      ({'콩나물'})   \n",
       "22      ({'콩나물'})    ({'찌개용두부'})  1.578839      ({'콩나물'})    ({'찌개용두부'})   \n",
       "2       ({'콩나물'})       ({'두부'})  1.547957      ({'콩나물'})       ({'두부'})   \n",
       "3        ({'두부'})      ({'콩나물'})  1.547957       ({'두부'})      ({'콩나물'})   \n",
       "6        ({'양파'})  ({'유정란/친환경'})  1.209997       ({'양파'})  ({'유정란/친환경'})   \n",
       "7   ({'유정란/친환경'})       ({'양파'})  1.209997  ({'유정란/친환경'})       ({'양파'})   \n",
       "8        ({'양파'})       ({'두부'})  1.195841       ({'양파'})       ({'두부'})   \n",
       "9        ({'두부'})       ({'양파'})  1.195841       ({'두부'})       ({'양파'})   \n",
       "20  ({'동물복지유정란'})       ({'두부'})  1.170426  ({'동물복지유정란'})       ({'두부'})   \n",
       "21       ({'두부'})  ({'동물복지유정란'})  1.170426       ({'두부'})  ({'동물복지유정란'})   \n",
       "16       ({'당근'})       ({'두부'})  1.163668       ({'당근'})       ({'두부'})   \n",
       "17       ({'두부'})       ({'당근'})  1.163668       ({'두부'})       ({'당근'})   \n",
       "0   ({'유정란/친환경'})       ({'두부'})  1.155821  ({'유정란/친환경'})       ({'두부'})   \n",
       "1        ({'두부'})  ({'유정란/친환경'})  1.155821       ({'두부'})  ({'유정란/친환경'})   \n",
       "14  ({'유정란/친환경'})       ({'당근'})  1.150401  ({'유정란/친환경'})       ({'당근'})   \n",
       "15       ({'당근'})  ({'유정란/친환경'})  1.150401       ({'당근'})  ({'유정란/친환경'})   \n",
       "13       ({'오이'})  ({'유정란/친환경'})  1.122162       ({'오이'})  ({'유정란/친환경'})   \n",
       "12  ({'유정란/친환경'})       ({'오이'})  1.122162  ({'유정란/친환경'})       ({'오이'})   \n",
       "5   ({'유정란/친환경'})      ({'콩나물'})  1.101436  ({'유정란/친환경'})      ({'콩나물'})   \n",
       "4       ({'콩나물'})  ({'유정란/친환경'})  1.101436      ({'콩나물'})  ({'유정란/친환경'})   \n",
       "11  ({'유정란/친환경'})    ({'찌개용두부'})  1.100126  ({'유정란/친환경'})    ({'찌개용두부'})   \n",
       "10    ({'찌개용두부'})  ({'유정란/친환경'})  1.100126    ({'찌개용두부'})  ({'유정란/친환경'})   \n",
       "18       ({'오이'})       ({'두부'})  1.098418       ({'오이'})       ({'두부'})   \n",
       "19       ({'두부'})       ({'오이'})  1.098418       ({'두부'})       ({'오이'})   \n",
       "\n",
       "        lift    antecedents    consequents      lift    antecedents  \\\n",
       "23  1.578839    ({'찌개용두부'})      ({'콩나물'})  1.578839    ({'찌개용두부'})   \n",
       "22  1.578839      ({'콩나물'})    ({'찌개용두부'})  1.578839      ({'콩나물'})   \n",
       "2   1.547957      ({'콩나물'})       ({'두부'})  1.547957      ({'콩나물'})   \n",
       "3   1.547957       ({'두부'})      ({'콩나물'})  1.547957       ({'두부'})   \n",
       "6   1.209997       ({'양파'})  ({'유정란/친환경'})  1.209997       ({'양파'})   \n",
       "7   1.209997  ({'유정란/친환경'})       ({'양파'})  1.209997  ({'유정란/친환경'})   \n",
       "8   1.195841       ({'양파'})       ({'두부'})  1.195841       ({'양파'})   \n",
       "9   1.195841       ({'두부'})       ({'양파'})  1.195841       ({'두부'})   \n",
       "20  1.170426  ({'동물복지유정란'})       ({'두부'})  1.170426  ({'동물복지유정란'})   \n",
       "21  1.170426       ({'두부'})  ({'동물복지유정란'})  1.170426       ({'두부'})   \n",
       "16  1.163668       ({'당근'})       ({'두부'})  1.163668       ({'당근'})   \n",
       "17  1.163668       ({'두부'})       ({'당근'})  1.163668       ({'두부'})   \n",
       "0   1.155821  ({'유정란/친환경'})       ({'두부'})  1.155821  ({'유정란/친환경'})   \n",
       "1   1.155821       ({'두부'})  ({'유정란/친환경'})  1.155821       ({'두부'})   \n",
       "14  1.150401  ({'유정란/친환경'})       ({'당근'})  1.150401  ({'유정란/친환경'})   \n",
       "15  1.150401       ({'당근'})  ({'유정란/친환경'})  1.150401       ({'당근'})   \n",
       "13  1.122162       ({'오이'})  ({'유정란/친환경'})  1.122162       ({'오이'})   \n",
       "12  1.122162  ({'유정란/친환경'})       ({'오이'})  1.122162  ({'유정란/친환경'})   \n",
       "5   1.101436  ({'유정란/친환경'})      ({'콩나물'})  1.101436  ({'유정란/친환경'})   \n",
       "4   1.101436      ({'콩나물'})  ({'유정란/친환경'})  1.101436      ({'콩나물'})   \n",
       "11  1.100126  ({'유정란/친환경'})    ({'찌개용두부'})  1.100126  ({'유정란/친환경'})   \n",
       "10  1.100126    ({'찌개용두부'})  ({'유정란/친환경'})  1.100126    ({'찌개용두부'})   \n",
       "18  1.098418       ({'오이'})       ({'두부'})  1.098418       ({'오이'})   \n",
       "19  1.098418       ({'두부'})       ({'오이'})  1.098418       ({'두부'})   \n",
       "\n",
       "      consequents      lift    antecedents    consequents      lift  \\\n",
       "23      ({'콩나물'})  1.578839    ({'찌개용두부'})      ({'콩나물'})  1.578839   \n",
       "22    ({'찌개용두부'})  1.578839      ({'콩나물'})    ({'찌개용두부'})  1.578839   \n",
       "2        ({'두부'})  1.547957      ({'콩나물'})       ({'두부'})  1.547957   \n",
       "3       ({'콩나물'})  1.547957       ({'두부'})      ({'콩나물'})  1.547957   \n",
       "6   ({'유정란/친환경'})  1.209997       ({'양파'})  ({'유정란/친환경'})  1.209997   \n",
       "7        ({'양파'})  1.209997  ({'유정란/친환경'})       ({'양파'})  1.209997   \n",
       "8        ({'두부'})  1.195841       ({'양파'})       ({'두부'})  1.195841   \n",
       "9        ({'양파'})  1.195841       ({'두부'})       ({'양파'})  1.195841   \n",
       "20       ({'두부'})  1.170426  ({'동물복지유정란'})       ({'두부'})  1.170426   \n",
       "21  ({'동물복지유정란'})  1.170426       ({'두부'})  ({'동물복지유정란'})  1.170426   \n",
       "16       ({'두부'})  1.163668       ({'당근'})       ({'두부'})  1.163668   \n",
       "17       ({'당근'})  1.163668       ({'두부'})       ({'당근'})  1.163668   \n",
       "0        ({'두부'})  1.155821  ({'유정란/친환경'})       ({'두부'})  1.155821   \n",
       "1   ({'유정란/친환경'})  1.155821       ({'두부'})  ({'유정란/친환경'})  1.155821   \n",
       "14       ({'당근'})  1.150401  ({'유정란/친환경'})       ({'당근'})  1.150401   \n",
       "15  ({'유정란/친환경'})  1.150401       ({'당근'})  ({'유정란/친환경'})  1.150401   \n",
       "13  ({'유정란/친환경'})  1.122162       ({'오이'})  ({'유정란/친환경'})  1.122162   \n",
       "12       ({'오이'})  1.122162  ({'유정란/친환경'})       ({'오이'})  1.122162   \n",
       "5       ({'콩나물'})  1.101436  ({'유정란/친환경'})      ({'콩나물'})  1.101436   \n",
       "4   ({'유정란/친환경'})  1.101436      ({'콩나물'})  ({'유정란/친환경'})  1.101436   \n",
       "11    ({'찌개용두부'})  1.100126  ({'유정란/친환경'})    ({'찌개용두부'})  1.100126   \n",
       "10  ({'유정란/친환경'})  1.100126    ({'찌개용두부'})  ({'유정란/친환경'})  1.100126   \n",
       "18       ({'두부'})  1.098418       ({'오이'})       ({'두부'})  1.098418   \n",
       "19       ({'오이'})  1.098418       ({'두부'})       ({'오이'})  1.098418   \n",
       "\n",
       "      antecedents    consequents      lift  \n",
       "23    ({'찌개용두부'})      ({'콩나물'})  1.578839  \n",
       "22      ({'콩나물'})    ({'찌개용두부'})  1.578839  \n",
       "2       ({'콩나물'})       ({'두부'})  1.547957  \n",
       "3        ({'두부'})      ({'콩나물'})  1.547957  \n",
       "6        ({'양파'})  ({'유정란/친환경'})  1.209997  \n",
       "7   ({'유정란/친환경'})       ({'양파'})  1.209997  \n",
       "8        ({'양파'})       ({'두부'})  1.195841  \n",
       "9        ({'두부'})       ({'양파'})  1.195841  \n",
       "20  ({'동물복지유정란'})       ({'두부'})  1.170426  \n",
       "21       ({'두부'})  ({'동물복지유정란'})  1.170426  \n",
       "16       ({'당근'})       ({'두부'})  1.163668  \n",
       "17       ({'두부'})       ({'당근'})  1.163668  \n",
       "0   ({'유정란/친환경'})       ({'두부'})  1.155821  \n",
       "1        ({'두부'})  ({'유정란/친환경'})  1.155821  \n",
       "14  ({'유정란/친환경'})       ({'당근'})  1.150401  \n",
       "15       ({'당근'})  ({'유정란/친환경'})  1.150401  \n",
       "13       ({'오이'})  ({'유정란/친환경'})  1.122162  \n",
       "12  ({'유정란/친환경'})       ({'오이'})  1.122162  \n",
       "5   ({'유정란/친환경'})      ({'콩나물'})  1.101436  \n",
       "4       ({'콩나물'})  ({'유정란/친환경'})  1.101436  \n",
       "11  ({'유정란/친환경'})    ({'찌개용두부'})  1.100126  \n",
       "10    ({'찌개용두부'})  ({'유정란/친환경'})  1.100126  \n",
       "18       ({'오이'})       ({'두부'})  1.098418  \n",
       "19       ({'두부'})       ({'오이'})  1.098418  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([df, df2, df3, df4, df5,df6], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbf59628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "415c0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('연관규칙(물품명) 연령별 비교.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b156b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edf489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbc99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb9b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39900e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing 1190 combinations | Sampling itemset size 2\r\n",
      "Processing 390 combinations | Sampling itemset size 3\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/home/piai/강의파일/프로젝트/구매상품데이터프레임(물품명)처음.csv\",index_col=0)\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    records.append([str(df.values[i,j]) \\\n",
    "                    for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])\n",
    "\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records, sparse=True)\n",
    "te_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "frequent_itemset = apriori(te_df,\n",
    "                           min_support=0.005, \n",
    "                           max_len=3, \n",
    "                           use_colnames=True, \n",
    "                           verbose=1 \n",
    "                          )\n",
    "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
    "frequent_itemset.sort_values('support',ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "association_rules_df = association_rules(frequent_itemset, \n",
    "                                         metric='confidence', \n",
    "                                         min_threshold=0.005,\n",
    "                                        )\n",
    "all_confidences = []\n",
    "collective_strengths = []\n",
    "cosine_similarities = []\n",
    "for _,row in association_rules_df.iterrows():\n",
    "    all_confidence_if = list(row['antecedents'])[0]\n",
    "    all_confidence_then = list(row['consequents'])[0]\n",
    "    if row['antecedent support'] <= row['consequent support']:\n",
    "        all_confidence_if = list(row['consequents'])[0]\n",
    "        all_confidence_then = list(row['antecedents'])[0]\n",
    "    all_confidence = {all_confidence_if+' => '+all_confidence_then : \\\n",
    "                      row['support']/max(row['antecedent support'], row['consequent support'])}\n",
    "    all_confidences.append(all_confidence)\n",
    "    \n",
    "    violation = row['antecedent support'] + row['consequent support'] - 2*row['support']\n",
    "    ex_violation = 1-row['antecedent support']*row['consequent support'] - \\\n",
    "                    (1-row['antecedent support'])*(1-row['consequent support'])\n",
    "    if violation == 0 or ex_violation == 0:\n",
    "        collective_strength = 0\n",
    "    else:\n",
    "        collective_strength = (1-violation)/(1-ex_violation)*(ex_violation/violation+1)+1\n",
    "    collective_strengths.append(collective_strength)\n",
    "    \n",
    "    cosine_similarity = row['support']/np.sqrt(row['antecedent support']*row['consequent support'])\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "    \n",
    "association_rules_df['all-confidence'] = all_confidences\n",
    "association_rules_df['collective strength'] = collective_strengths\n",
    "association_rules_df['cosine similarity'] = cosine_similarities\n",
    "\n",
    "df_association = association_rules_df.sort_values(by='lift',ascending=False)\n",
    "\n",
    "df_association\n",
    "\n",
    "df_association.to_csv('연관규칙(물품명)처음.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168296f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
